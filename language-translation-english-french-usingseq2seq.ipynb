{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1067156,"sourceType":"datasetVersion","datasetId":592212}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:36:56.099452Z","iopub.execute_input":"2025-01-02T09:36:56.099777Z","iopub.status.idle":"2025-01-02T09:36:56.113638Z","shell.execute_reply.started":"2025-01-02T09:36:56.099752Z","shell.execute_reply":"2025-01-02T09:36:56.112784Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/language-translation-englishfrench/eng_-french.csv\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# **Important Libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport re\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Bidirectional, Concatenate, Layer\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T10:29:15.382849Z","iopub.execute_input":"2025-01-02T10:29:15.383151Z","iopub.status.idle":"2025-01-02T10:29:15.388024Z","shell.execute_reply.started":"2025-01-02T10:29:15.383128Z","shell.execute_reply":"2025-01-02T10:29:15.387068Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"# **Load Dataset**","metadata":{}},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv('/kaggle/input/language-translation-englishfrench/eng_-french.csv', names=[\"English\", \"French\"], header=0)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:36:56.125913Z","iopub.execute_input":"2025-01-02T09:36:56.126178Z","iopub.status.idle":"2025-01-02T09:36:56.421619Z","shell.execute_reply.started":"2025-01-02T09:36:56.126151Z","shell.execute_reply":"2025-01-02T09:36:56.420706Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"  English      French\n0     Hi.      Salut!\n1    Run!     Cours !\n2    Run!    Courez !\n3    Who?       Qui ?\n4    Wow!  Ça alors !","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>Salut!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Who?</td>\n      <td>Qui ?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"# **Data Cleaning and Spliting**","metadata":{}},{"cell_type":"code","source":"# Clean English text\ndef clean_english_text(text):\n    text = text.lower()\n    contractions = {\n        \"i'm\": \"i am\", \"you're\": \"you are\", \"it's\": \"it is\",\n        \"can't\": \"cannot\", \"don't\": \"do not\", \"didn't\": \"did not\",\n        \"i've\": \"i have\", \"we're\": \"we are\", \"isn't\": \"is not\",\n        \"won't\": \"will not\", \"aren't\": \"are not\"\n    }\n    for contraction, full_form in contractions.items():\n        text = re.sub(r'\\b{}\\b'.format(contraction), full_form, text)\n    text = re.sub(r\"[^a-z\\s]+\", \"\", text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\n# Clean French text\ndef clean_french_text(text):\n    text = text.lower()\n    contractions = {\n        \"c'est\": \"ce est\", \"j'ai\": \"je ai\", \"il y a\": \"il y avoir\",\n        \"n'est\": \"ne est\", \"qu'est\": \"que est\", \"d'accord\": \"de accord\"\n    }\n    for contraction, full_form in contractions.items():\n        text = re.sub(r'\\b{}\\b'.format(contraction), full_form, text)\n    text = re.sub(r\"[^a-z\\u00e0\\u00e8\\u00e9\\u00e2\\u00ea\\u00ee\\u00f4\\u00fb\\u00e7\\u00f9\\u00ef\\u00fc\\u0153\\s]+\", \"\", text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:36:56.423009Z","iopub.execute_input":"2025-01-02T09:36:56.423355Z","iopub.status.idle":"2025-01-02T09:36:56.429438Z","shell.execute_reply.started":"2025-01-02T09:36:56.423321Z","shell.execute_reply":"2025-01-02T09:36:56.428441Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Apply text cleaning\ndf[\"English\"] = df[\"English\"].apply(clean_english_text)\ndf[\"French\"] = df[\"French\"].apply(clean_french_text)\n\n# Add special tokens for French sequences\ndf[\"French\"] = df[\"French\"].apply(lambda x: f\"<start> {x} <end>\")\n\n# Extract cleaned sentences\nenglish_sentences = df[\"English\"].tolist()\nfrench_sentences = df[\"French\"].tolist()\nprint(\"Cleaned English Sentences:\", english_sentences[:5])\nprint(\"Cleaned French Sentences:\", french_sentences[:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:36:56.430560Z","iopub.execute_input":"2025-01-02T09:36:56.430822Z","iopub.status.idle":"2025-01-02T09:37:03.459184Z","shell.execute_reply.started":"2025-01-02T09:36:56.430799Z","shell.execute_reply":"2025-01-02T09:37:03.458406Z"}},"outputs":[{"name":"stdout","text":"Cleaned English Sentences: ['hi', 'run', 'run', 'who', 'wow']\nCleaned French Sentences: ['<start> salut <end>', '<start> cours <end>', '<start> courez <end>', '<start> qui <end>', '<start> ça alors <end>']\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Split data\ntrain_english, test_english, train_french, test_french = train_test_split(\n    df[\"English\"], df[\"French\"], test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:37:03.459910Z","iopub.execute_input":"2025-01-02T09:37:03.460120Z","iopub.status.idle":"2025-01-02T09:37:03.509579Z","shell.execute_reply.started":"2025-01-02T09:37:03.460101Z","shell.execute_reply":"2025-01-02T09:37:03.508807Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# **Tokenization**","metadata":{}},{"cell_type":"code","source":"# Preprocessing function\ndef preprocess_text(tokenizer, texts, max_len):\n    sequences = tokenizer.texts_to_sequences(texts)\n    return pad_sequences(sequences, maxlen=max_len, padding='post')\n\n# Tokenization and Padding\nmax_vocab_size = 10000\nmax_sequence_length = 20\n\nenglish_tokenizer = Tokenizer(num_words=max_vocab_size)\nenglish_tokenizer.fit_on_texts(train_english)\n\nfrench_tokenizer = Tokenizer(num_words=max_vocab_size)\nfrench_tokenizer.fit_on_texts(train_french)\n\ntrain_english_padded = preprocess_text(english_tokenizer, train_english, max_sequence_length)\ntrain_french_padded = preprocess_text(french_tokenizer, train_french, max_sequence_length)\ntest_english_padded = preprocess_text(english_tokenizer, test_english, max_sequence_length)\ntest_french_padded = preprocess_text(french_tokenizer, test_french, max_sequence_length)\n\n# Prepare decoder target sequences\ntrain_decoder_target_data = train_french_padded[:, 1:]\ntrain_decoder_target_data = pad_sequences(train_decoder_target_data, maxlen=max_sequence_length, padding='post')\n\n# Vocabulary sizes\nenglish_vocab_size = len(english_tokenizer.word_index) + 1\nfrench_vocab_size = len(french_tokenizer.word_index) + 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:37:03.510460Z","iopub.execute_input":"2025-01-02T09:37:03.510825Z","iopub.status.idle":"2025-01-02T09:37:11.446696Z","shell.execute_reply.started":"2025-01-02T09:37:03.510797Z","shell.execute_reply":"2025-01-02T09:37:11.446056Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"# **Model**","metadata":{}},{"cell_type":"code","source":"# Custom Attention Layer\nclass AttentionLayer(Layer):\n    def call(self, inputs):\n        decoder_outputs, encoder_outputs = inputs\n        attention_scores = tf.matmul(decoder_outputs, encoder_outputs, transpose_b=True)\n        attention_weights = tf.nn.softmax(attention_scores, axis=-1)\n        context_vector = tf.matmul(attention_weights, encoder_outputs)\n        return context_vector","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:37:11.448861Z","iopub.execute_input":"2025-01-02T09:37:11.449102Z","iopub.status.idle":"2025-01-02T09:37:11.453190Z","shell.execute_reply.started":"2025-01-02T09:37:11.449080Z","shell.execute_reply":"2025-01-02T09:37:11.452377Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Seq2Seq Model with Bidirectional LSTM and Attention Mechanism\nencoder_inputs = Input(shape=(max_sequence_length,))\nencoder_embedding = Embedding(input_dim=english_vocab_size, output_dim=256, mask_zero=True)(encoder_inputs)\nencoder_lstm = Bidirectional(LSTM(256, return_sequences=True, return_state=True))\nencoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_lstm(encoder_embedding)\nstate_h = Concatenate()([forward_h, backward_h])\nstate_c = Concatenate()([forward_c, backward_c])\nencoder_states = [state_h, state_c]\n\ndecoder_inputs = Input(shape=(max_sequence_length,))\ndecoder_embedding = Embedding(input_dim=french_vocab_size, output_dim=256, mask_zero=True)(decoder_inputs)\ndecoder_lstm = LSTM(512, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n\nattention_layer = AttentionLayer()\nattention_result = attention_layer([decoder_outputs, encoder_outputs])\ndecoder_concat_input = Concatenate(axis=-1)([decoder_outputs, attention_result])\n\ndecoder_dense = Dense(french_vocab_size, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_concat_input)\n\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:37:11.454255Z","iopub.execute_input":"2025-01-02T09:37:11.454585Z","iopub.status.idle":"2025-01-02T09:37:11.737357Z","shell.execute_reply.started":"2025-01-02T09:37:11.454563Z","shell.execute_reply":"2025-01-02T09:37:11.736518Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'attention_layer_1' (of type AttentionLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_5\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_15            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │      \u001b[38;5;34m3,432,448\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ not_equal_2 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ input_layer_16            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bidirectional_2           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │      \u001b[38;5;34m1,050,624\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│                           │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │                │                        │\n│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]           │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │      \u001b[38;5;34m6,824,704\u001b[0m │ input_layer_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m3\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m4\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │      \u001b[38;5;34m1,574,912\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ concatenate_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                           │ \u001b[38;5;34m512\u001b[0m)]                  │                │ concatenate_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_layer_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│ (\u001b[38;5;33mAttentionLayer\u001b[0m)          │                        │                │ bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ attention_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m26659\u001b[0m)      │     \u001b[38;5;34m27,325,475\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_15            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,432,448</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ not_equal_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ input_layer_16            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bidirectional_2           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │                │                        │\n│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]           │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,824,704</span> │ input_layer_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]                  │                │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_layer_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)          │                        │                │ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ attention_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26659</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,325,475</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,208,163\u001b[0m (153.38 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,208,163</span> (153.38 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,208,163\u001b[0m (153.38 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,208,163</span> (153.38 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# Train the model with EarlyStopping callbacks\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n\nmodel.fit(\n    [train_english_padded, train_french_padded],\n    np.expand_dims(train_decoder_target_data, -1),\n    batch_size=64,\n    epochs=10,\n    validation_split=0.2,\n    callbacks=[early_stopping_callback]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:37:11.738249Z","iopub.execute_input":"2025-01-02T09:37:11.738592Z","iopub.status.idle":"2025-01-02T10:25:41.109966Z","shell.execute_reply.started":"2025-01-02T09:37:11.738557Z","shell.execute_reply":"2025-01-02T10:25:41.109157Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m1757/1757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 207ms/step - accuracy: 0.7242 - loss: 2.0910 - val_accuracy: 0.8444 - val_loss: 0.8451\nEpoch 2/10\n\u001b[1m1757/1757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 207ms/step - accuracy: 0.8621 - loss: 0.6943 - val_accuracy: 0.8776 - val_loss: 0.5987\nEpoch 3/10\n\u001b[1m1757/1757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 207ms/step - accuracy: 0.8981 - loss: 0.4394 - val_accuracy: 0.8891 - val_loss: 0.5255\nEpoch 4/10\n\u001b[1m1757/1757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 207ms/step - accuracy: 0.9177 - loss: 0.3252 - val_accuracy: 0.8939 - val_loss: 0.5001\nEpoch 5/10\n\u001b[1m1757/1757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 206ms/step - accuracy: 0.9314 - loss: 0.2566 - val_accuracy: 0.8966 - val_loss: 0.4969\nEpoch 6/10\n\u001b[1m1757/1757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 207ms/step - accuracy: 0.9416 - loss: 0.2096 - val_accuracy: 0.8976 - val_loss: 0.5014\nEpoch 7/10\n\u001b[1m1757/1757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 207ms/step - accuracy: 0.9497 - loss: 0.1756 - val_accuracy: 0.8982 - val_loss: 0.5123\nEpoch 8/10\n\u001b[1m1757/1757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 207ms/step - accuracy: 0.9559 - loss: 0.1504 - val_accuracy: 0.8980 - val_loss: 0.5252\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d66204520e0>"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"# **Evaluate and Prediciton**","metadata":{}},{"cell_type":"code","source":"# Evaluate the model\ntest_decoder_target_data = test_french_padded[:, 1:]\ntest_decoder_target_data = pad_sequences(test_decoder_target_data, maxlen=max_sequence_length, padding='post')\nloss, accuracy = model.evaluate(\n    [test_english_padded, test_french_padded],\n    np.expand_dims(test_decoder_target_data, -1)\n)\nprint(f\"Test Loss: {loss:.2f}, Test Accuracy: {accuracy:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T10:25:41.110930Z","iopub.execute_input":"2025-01-02T10:25:41.111257Z","iopub.status.idle":"2025-01-02T10:26:35.940418Z","shell.execute_reply.started":"2025-01-02T10:25:41.111224Z","shell.execute_reply":"2025-01-02T10:26:35.939663Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 50ms/step - accuracy: 0.8979 - loss: 0.5149\nTest Loss: 0.52, Test Accuracy: 0.90\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Inference models with Attention Mechanism\nencoder_model = Model(encoder_inputs, [encoder_outputs] + encoder_states)\n\ndecoder_state_input_h = Input(shape=(512,))\ndecoder_state_input_c = Input(shape=(512,))\ndecoder_hidden_states_input = Input(shape=(max_sequence_length, 512))\n\ndecoder_lstm_outputs, state_h_decoded, state_c_decoded = decoder_lstm(\n    decoder_embedding,\n    initial_state=[decoder_state_input_h, decoder_state_input_c]\n)\nattention_result_decoded = attention_layer([decoder_lstm_outputs, decoder_hidden_states_input])\ndecoder_concat_input_decoded = Concatenate(axis=-1)([decoder_lstm_outputs, attention_result_decoded])\ndecoder_outputs_decoded = decoder_dense(decoder_concat_input_decoded)\n\ndecoder_model = Model(\n    [decoder_inputs] + [decoder_state_input_h, decoder_state_input_c, decoder_hidden_states_input],\n    [decoder_outputs_decoded] + [state_h_decoded, state_c_decoded]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T10:27:34.095573Z","iopub.execute_input":"2025-01-02T10:27:34.095869Z","iopub.status.idle":"2025-01-02T10:27:34.116021Z","shell.execute_reply.started":"2025-01-02T10:27:34.095846Z","shell.execute_reply":"2025-01-02T10:27:34.114985Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'attention_layer_1' (of type AttentionLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Reverse lookup for French vocabulary\nreverse_french_vocab = {i: word for word, i in french_tokenizer.word_index.items()}\n\ndef decode_sequence(input_seq):\n    encoder_outputs, state_h, state_c = encoder_model.predict(input_seq, verbose=0)  \n    states_value = [state_h, state_c]\n    target_seq = np.zeros((1, 1))\n    target_seq[0, 0] = french_tokenizer.word_index.get('<start>', 0)\n\n    decoded_sentence = ''\n    for _ in range(max_sequence_length): \n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value + [encoder_outputs],verbose=0)\n        \n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_word = reverse_french_vocab.get(sampled_token_index, '')\n\n        if sampled_word == '<end>':\n            break\n\n        # Append the word to the sentence\n        decoded_sentence += ' ' + sampled_word\n        target_seq[0, 0] = sampled_token_index\n        states_value = [h, c]\n\n    return decoded_sentence.replace('end','').strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T10:27:34.708247Z","iopub.execute_input":"2025-01-02T10:27:34.708601Z","iopub.status.idle":"2025-01-02T10:27:34.719193Z","shell.execute_reply.started":"2025-01-02T10:27:34.708574Z","shell.execute_reply":"2025-01-02T10:27:34.718393Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# Create a list to store the actual and predicted translations\ntranslations = []\n\n# Generate 15 random indices within the range of the test dataset\nrandom_indices = random.sample(range(len(test_english_padded)), 10)\n\n# Test translations for randomly selected indices\nfor i in random_indices:\n    input_seq = test_english_padded[i:i + 1]\n    translated_sentence = decode_sequence(input_seq)\n    actual_sentence = test_french.iloc[i]\n    \n    # Append both actual and predicted sentences to the list\n    translations.append({\"Actual\": actual_sentence, \"Predicted\": translated_sentence})\n\n# Convert the list to a DataFrame\ntranslations_df = pd.DataFrame(translations)\n\n# Print the DataFrame with actual and predicted translations\ntranslations_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T10:30:49.298904Z","iopub.execute_input":"2025-01-02T10:30:49.299198Z","iopub.status.idle":"2025-01-02T10:31:02.683683Z","shell.execute_reply.started":"2025-01-02T10:30:49.299175Z","shell.execute_reply":"2025-01-02T10:31:02.682650Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"                                              Actual  \\\n0      <start> êtesvous le gérant de la banque <end>   \n1     <start> lauraisje su je vous laurais dit <end>   \n2  <start> elle dut utiliser son dictionnaire à d...   \n3  <start> tu compares des choux et des carottes ...   \n4  <start> avezvous un dictionnaire de français <...   \n5  <start> je ne voulais pas que la vérité surgis...   \n6       <start> je ne peux pas te promettre ça <end>   \n7            <start> regarde ce que tu as fait <end>   \n8               <start> nastu pas lu le manuel <end>   \n9                  <start> je ne dors pas bien <end>   \n\n                              Predicted  \n0                 êtesvous le directeur  \n1                si je vous laurais dit  \n2   elle a de utiliser son dictionnaire  \n3  vous êtes des pommes et des carottes  \n4     avezvous un dictionnaire français  \n5              je ne voulais pas sortir  \n6           je ne peux pas te promettre  \n7     tas fait de ce que vous avez fait  \n8            avezvous plus lu le manuel  \n9                   je ne vais pas bien  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual</th>\n      <th>Predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;start&gt; êtesvous le gérant de la banque &lt;end&gt;</td>\n      <td>êtesvous le directeur</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;start&gt; lauraisje su je vous laurais dit &lt;end&gt;</td>\n      <td>si je vous laurais dit</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;start&gt; elle dut utiliser son dictionnaire à d...</td>\n      <td>elle a de utiliser son dictionnaire</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;start&gt; tu compares des choux et des carottes ...</td>\n      <td>vous êtes des pommes et des carottes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;start&gt; avezvous un dictionnaire de français &lt;...</td>\n      <td>avezvous un dictionnaire français</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>&lt;start&gt; je ne voulais pas que la vérité surgis...</td>\n      <td>je ne voulais pas sortir</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>&lt;start&gt; je ne peux pas te promettre ça &lt;end&gt;</td>\n      <td>je ne peux pas te promettre</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>&lt;start&gt; regarde ce que tu as fait &lt;end&gt;</td>\n      <td>tas fait de ce que vous avez fait</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>&lt;start&gt; nastu pas lu le manuel &lt;end&gt;</td>\n      <td>avezvous plus lu le manuel</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>&lt;start&gt; je ne dors pas bien &lt;end&gt;</td>\n      <td>je ne vais pas bien</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}